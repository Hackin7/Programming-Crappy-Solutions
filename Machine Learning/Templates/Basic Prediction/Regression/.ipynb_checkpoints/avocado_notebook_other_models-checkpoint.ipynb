{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avocado Data Analysis Notebook\n",
    "ALT-TAB LABS LLP &copy; 2020 All Rights Reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['75%.py',\n '80%.ipynb',\n 'avocado-submission.csv',\n 'avocado-test.csv',\n 'avocado-train.csv',\n 'avocado_notebook_other_models.ipynb',\n 'pipeline test.ipynb',\n 'pyctfsglib.py',\n '__pycache__']"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show files in current directory\n",
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataBatch</th>\n      <th>Date</th>\n      <th>TotalVolume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>TotalBags</th>\n      <th>SmallBags</th>\n      <th>LargeBags</th>\n      <th>XLargeBags</th>\n      <th>type</th>\n      <th>region</th>\n      <th>AveragePrice</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>2016-11-06</td>\n      <td>183542.31</td>\n      <td>98949.98</td>\n      <td>22891.61</td>\n      <td>95.00</td>\n      <td>61605.72</td>\n      <td>43571.99</td>\n      <td>17499.01</td>\n      <td>534.72</td>\n      <td>conventional</td>\n      <td>NewOrleansMobile</td>\n      <td>1.49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>2017-07-16</td>\n      <td>224434.92</td>\n      <td>42951.31</td>\n      <td>120360.02</td>\n      <td>131.85</td>\n      <td>60991.74</td>\n      <td>53141.81</td>\n      <td>3621.04</td>\n      <td>4228.89</td>\n      <td>conventional</td>\n      <td>HarrisburgScranton</td>\n      <td>1.38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51</td>\n      <td>2015-01-04</td>\n      <td>3846.69</td>\n      <td>1500.15</td>\n      <td>938.35</td>\n      <td>0.00</td>\n      <td>1408.19</td>\n      <td>1071.35</td>\n      <td>336.84</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>Atlanta</td>\n      <td>1.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>2015-07-26</td>\n      <td>91825.07</td>\n      <td>1679.28</td>\n      <td>45615.48</td>\n      <td>741.77</td>\n      <td>43788.54</td>\n      <td>43788.54</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>BuffaloRochester</td>\n      <td>1.39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>2015-01-11</td>\n      <td>54644.32</td>\n      <td>1491.88</td>\n      <td>33759.12</td>\n      <td>1325.17</td>\n      <td>18068.15</td>\n      <td>12165.94</td>\n      <td>5902.21</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>Pittsburgh</td>\n      <td>1.54</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    DataBatch        Date  TotalVolume      4046       4225     4770  \\\nid                                                                     \n0           7  2016-11-06    183542.31  98949.98   22891.61    95.00   \n1          24  2017-07-16    224434.92  42951.31  120360.02   131.85   \n2          51  2015-01-04      3846.69   1500.15     938.35     0.00   \n3          22  2015-07-26     91825.07   1679.28   45615.48   741.77   \n4          50  2015-01-11     54644.32   1491.88   33759.12  1325.17   \n\n    TotalBags  SmallBags  LargeBags  XLargeBags          type  \\\nid                                                              \n0    61605.72   43571.99   17499.01      534.72  conventional   \n1    60991.74   53141.81    3621.04     4228.89  conventional   \n2     1408.19    1071.35     336.84        0.00       organic   \n3    43788.54   43788.54       0.00        0.00  conventional   \n4    18068.15   12165.94    5902.21        0.00  conventional   \n\n                region  AveragePrice  \nid                                    \n0     NewOrleansMobile          1.49  \n1   HarrisburgScranton          1.38  \n2              Atlanta          1.76  \n3     BuffaloRochester          1.39  \n4           Pittsburgh          1.54  "
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csvs\n",
    "import pandas as pd\n",
    "df = pd.read_csv('avocado-train.csv', index_col='id')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dealing with Missing Values ########################################################\n",
    "# https://www.kaggle.com/alexisbcook/missing-values\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "def dropColumns(X_train, X_valid):\n",
    "    # Get names of columns with missing values\n",
    "    cols_with_missing = [col for col in X_train.columns\n",
    "                        if X_train[col].isnull().any()]\n",
    "\n",
    "    # Drop columns in training and validation data\n",
    "    reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "    reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "    return reduced_X_train, reduced_X_valid\n",
    "\n",
    "\n",
    "def imputing(X_train, X_valid):\n",
    "    # Imputation\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    my_imputer = SimpleImputer()\n",
    "    imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "    imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "    # Imputation removed column names; put them back\n",
    "    imputed_X_train.columns = X_train.columns\n",
    "    imputed_X_valid.columns = X_valid.columns\n",
    "    return imputed_X_train, imputed_X_valid\n",
    "\n",
    "def imputePlus(X_train, X_valid):\n",
    "    X_train_plus = X_train.copy()\n",
    "    X_valid_plus = X_valid.copy()\n",
    "\n",
    "    # Make new columns indicating what will be imputed\n",
    "    # Get names of columns with missing values\n",
    "    cols_with_missing = [col for col in X_train.columns\n",
    "                        if X_train[col].isnull().any()]\n",
    "    for col in cols_with_missing:\n",
    "        X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "        X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "    # Imputation\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    my_imputer = SimpleImputer()\n",
    "    imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "    imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "    # Imputation removed column names; put them back\n",
    "    imputed_X_train_plus.columns = X_train_plus.columns\n",
    "    imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "    return imputed_X_train_plus, imputed_X_valid_plus\n",
    "\n",
    "### Dealing with Categorial Variables ##################################################\n",
    "def getNumericColumns(X):\n",
    "    return [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "    \n",
    "def getCategories(X_train):\n",
    "    # Get list of categorical variables\n",
    "    s = (X_train.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    return object_cols\n",
    "\n",
    "def dropCategories(X_train, X_valid):\n",
    "    object_cols = getCategories(X_train)\n",
    "    drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "    drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "    return drop_X_train, drop_X_valid, Y_train, Y_valid\n",
    "\n",
    "# Label Encoding\n",
    "def labelEncoding(X_train, X_valid):\n",
    "    object_cols = getCategories(X_train)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    # Make copy to avoid changing original data \n",
    "    label_X_train = X_train.copy()\n",
    "    label_X_valid = X_valid.copy()\n",
    "\n",
    "    # Apply label encoder to each column with categorical data\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in object_cols:\n",
    "        label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "        label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "\n",
    "    return label_X_train, label_X_valid, Y_train, Y_valid\n",
    "\n",
    "### One Hot Encoding\n",
    "def oneHotEncoding(X_train, X_valid, debug=True):\n",
    "    object_cols = getCategories(X_train)\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    # Apply one-hot encoder to each column with categorical data\n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "    OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = X_train.index\n",
    "    OH_cols_valid.index = X_valid.index\n",
    "\n",
    "    # Remove categorical columns (will replace with one-hot encoding)\n",
    "    num_X_train = X_train.drop(object_cols, axis=1)\n",
    "    num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical features\n",
    "    OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "    OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "    return OH_X_train, OH_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "training split:  8558 ; test split:  4216\n"
    }
   ],
   "source": [
    "# Convert strings to numbers\n",
    "c = getNumericColumns(df)\n",
    "for column in c:\n",
    "    df[column] = pd.to_numeric(df[column])\n",
    "\n",
    "# Select data for learning\n",
    "features = c[:-1]+[\"type\",\"region\"]\n",
    "X = df[features]\n",
    "Y = df[\"AveragePrice\"]\n",
    "\n",
    "# Split training into some for training and some for testing\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "print(\"training split: \", len(X_train), \"; test split: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data!\n",
    "#df.head()\n",
    "X_train, X_test = oneHotEncoding(X_train, X_test)\n",
    "X_train, X_test = imputePlus(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataBatch</th>\n      <th>Date</th>\n      <th>TotalVolume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>TotalBags</th>\n      <th>SmallBags</th>\n      <th>LargeBags</th>\n      <th>XLargeBags</th>\n      <th>type</th>\n      <th>region</th>\n      <th>AveragePrice</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>2016-11-06</td>\n      <td>183542.31</td>\n      <td>98949.98</td>\n      <td>22891.61</td>\n      <td>95.00</td>\n      <td>61605.72</td>\n      <td>43571.99</td>\n      <td>17499.01</td>\n      <td>534.72</td>\n      <td>conventional</td>\n      <td>NewOrleansMobile</td>\n      <td>1.49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>2017-07-16</td>\n      <td>224434.92</td>\n      <td>42951.31</td>\n      <td>120360.02</td>\n      <td>131.85</td>\n      <td>60991.74</td>\n      <td>53141.81</td>\n      <td>3621.04</td>\n      <td>4228.89</td>\n      <td>conventional</td>\n      <td>HarrisburgScranton</td>\n      <td>1.38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51</td>\n      <td>2015-01-04</td>\n      <td>3846.69</td>\n      <td>1500.15</td>\n      <td>938.35</td>\n      <td>0.00</td>\n      <td>1408.19</td>\n      <td>1071.35</td>\n      <td>336.84</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>Atlanta</td>\n      <td>1.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>2015-07-26</td>\n      <td>91825.07</td>\n      <td>1679.28</td>\n      <td>45615.48</td>\n      <td>741.77</td>\n      <td>43788.54</td>\n      <td>43788.54</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>BuffaloRochester</td>\n      <td>1.39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>2015-01-11</td>\n      <td>54644.32</td>\n      <td>1491.88</td>\n      <td>33759.12</td>\n      <td>1325.17</td>\n      <td>18068.15</td>\n      <td>12165.94</td>\n      <td>5902.21</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>Pittsburgh</td>\n      <td>1.54</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    DataBatch        Date  TotalVolume      4046       4225     4770  \\\nid                                                                     \n0           7  2016-11-06    183542.31  98949.98   22891.61    95.00   \n1          24  2017-07-16    224434.92  42951.31  120360.02   131.85   \n2          51  2015-01-04      3846.69   1500.15     938.35     0.00   \n3          22  2015-07-26     91825.07   1679.28   45615.48   741.77   \n4          50  2015-01-11     54644.32   1491.88   33759.12  1325.17   \n\n    TotalBags  SmallBags  LargeBags  XLargeBags          type  \\\nid                                                              \n0    61605.72   43571.99   17499.01      534.72  conventional   \n1    60991.74   53141.81    3621.04     4228.89  conventional   \n2     1408.19    1071.35     336.84        0.00       organic   \n3    43788.54   43788.54       0.00        0.00  conventional   \n4    18068.15   12165.94    5902.21        0.00  conventional   \n\n                region  AveragePrice  \nid                                    \n0     NewOrleansMobile          1.49  \n1   HarrisburgScranton          1.38  \n2              Atlanta          1.76  \n3     BuffaloRochester          1.39  \n4           Pittsburgh          1.54  "
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfrom sklearn.preprocessing import StandardScaler\\nscX = StandardScaler()\\nscX.fit(X_train)\\nX_test = scX.transform(X_test)\\n\\n# Performng PCA\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components=None)\\npca.fit(X_train)\\nX_test = pca.transform(X_test)\\nexplainedvariance = pca.explained_variance_ratio_\\n\\n# Importing model\\nfrom sklearn.linear_model import LinearRegression\\nregressor = LinearRegression()\\nregressor.fit(X_train, Y_train)\\nregressor.score(X_test,Y_test)\\n'"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler()\n",
    "scX.fit(X_train)\n",
    "X_test = scX.transform(X_test)\n",
    "\n",
    "# Performng PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explainedvariance = pca.explained_variance_ratio_\n",
    "\n",
    "# Importing model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "regressor.score(X_test,Y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfrom sklearn.preprocessing import StandardScaler\\nscaler = StandardScaler()\\n# Fit only to the training data\\nscaler.fit(X_train)\\nX_train = scaler.transform(X_train)\\nX_test = scaler.transform(X_test)\\nY_train = np.asarray(Y_train, dtype=\"|S6\")\\nY_test = np.asarray(Y_test, dtype=\"|S6\")\\n\\nfrom sklearn.neural_network import MLPClassifier\\nmodel = MLPClassifier(hidden_layer_sizes=(30,30,30))\\nmodel.fit(X_train,Y_train)\\nmodel.score(X_train,Y_train)\\n'"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "Y_train = np.asarray(Y_train, dtype=\"|S6\")\n",
    "Y_test = np.asarray(Y_test, dtype=\"|S6\")\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_train,Y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sci Kit Learn! Scientific Computing library for python\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.6350478505550481\nDecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n                      max_features=None, max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, presort='deprecated',\n                      random_state=2020, splitter='best')\n0.8231919608917935\nRandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n                      max_samples=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      n_estimators=100, n_jobs=None, oob_score=False,\n                      random_state=2020, verbose=0, warm_start=False)\n"
    }
   ],
   "source": [
    "# Pick the regression model we want to use\n",
    "\n",
    "import sklearn.tree as tree\n",
    "models = [\n",
    "    tree.DecisionTreeRegressor(random_state=2020),\n",
    "    ensemble.RandomForestRegressor(random_state=2020, n_estimators=100)\n",
    "    #MLPClassifier(hidden_layer_sizes=(len(features),len(features),len(features)))\n",
    "]\n",
    "\n",
    "\n",
    "currScore = -10\n",
    "model = None\n",
    "for i in models:\n",
    "    #print(i)\n",
    "    i.fit(X_train,Y_train)\n",
    "    score = i.score(X_test,Y_test)\n",
    "    print(score)\n",
    "    if score > currScore:\n",
    "        model = i\n",
    "        print(model)\n",
    "        currScore = score\n",
    "\n",
    "# https://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.8231919608917935"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model\n",
    "model.score(X_test, Y_test) #TODO TODO TODO TODO TODO TODO TODO TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataBatch</th>\n      <th>Date</th>\n      <th>TotalVolume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>TotalBags</th>\n      <th>SmallBags</th>\n      <th>LargeBags</th>\n      <th>XLargeBags</th>\n      <th>type</th>\n      <th>region</th>\n      <th>AveragePrice</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>2016-07-31</td>\n      <td>183542.31</td>\n      <td>98949.98</td>\n      <td>22891.61</td>\n      <td>95.00</td>\n      <td>61605.72</td>\n      <td>43571.99</td>\n      <td>17499.01</td>\n      <td>534.72</td>\n      <td>organic</td>\n      <td>Chicago</td>\n      <td>1.49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>2017-08-20</td>\n      <td>224434.92</td>\n      <td>42951.31</td>\n      <td>120360.02</td>\n      <td>131.85</td>\n      <td>60991.74</td>\n      <td>53141.81</td>\n      <td>3621.04</td>\n      <td>4228.89</td>\n      <td>conventional</td>\n      <td>NorthernNewEngland</td>\n      <td>1.38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51</td>\n      <td>2017-01-22</td>\n      <td>3846.69</td>\n      <td>1500.15</td>\n      <td>938.35</td>\n      <td>0.00</td>\n      <td>1408.19</td>\n      <td>1071.35</td>\n      <td>336.84</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>GreatLakes</td>\n      <td>1.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>2015-10-04</td>\n      <td>91825.07</td>\n      <td>1679.28</td>\n      <td>45615.48</td>\n      <td>741.77</td>\n      <td>43788.54</td>\n      <td>43788.54</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>CincinnatiDayton</td>\n      <td>1.39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>2015-10-18</td>\n      <td>54644.32</td>\n      <td>1491.88</td>\n      <td>33759.12</td>\n      <td>1325.17</td>\n      <td>18068.15</td>\n      <td>12165.94</td>\n      <td>5902.21</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>Houston</td>\n      <td>1.54</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    DataBatch        Date  TotalVolume      4046       4225     4770  \\\nid                                                                     \n0           7  2016-07-31    183542.31  98949.98   22891.61    95.00   \n1          24  2017-08-20    224434.92  42951.31  120360.02   131.85   \n2          51  2017-01-22      3846.69   1500.15     938.35     0.00   \n3          22  2015-10-04     91825.07   1679.28   45615.48   741.77   \n4          50  2015-10-18     54644.32   1491.88   33759.12  1325.17   \n\n    TotalBags  SmallBags  LargeBags  XLargeBags          type  \\\nid                                                              \n0    61605.72   43571.99   17499.01      534.72       organic   \n1    60991.74   53141.81    3621.04     4228.89  conventional   \n2     1408.19    1071.35     336.84        0.00       organic   \n3    43788.54   43788.54       0.00        0.00       organic   \n4    18068.15   12165.94    5902.21        0.00       organic   \n\n                region  AveragePrice  \nid                                    \n0              Chicago          1.49  \n1   NorthernNewEngland          1.38  \n2           GreatLakes          1.76  \n3     CincinnatiDayton          1.39  \n4              Houston          1.54  "
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Data\n",
    "MyDataFrame = pd.read_csv('avocado-test.csv', index_col='id')\n",
    "# Drops missing values \n",
    "#MyDataFrame.dropna()\n",
    "# Convert strings to numbers\n",
    "# Convert strings to numbers\n",
    "c = getNumericColumns(df)\n",
    "for column in c:\n",
    "    MyDataFrame[column] = pd.to_numeric(df[column])\n",
    "MyDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "XforPredictions =  MyDataFrame[features]#None #TODO TODO TODO TODO TODO TODO TODO TODO\n",
    "\n",
    "#my_pipeline.fit(X_train, Y_train)\n",
    "# Preprocessing of validation data, get predictions\n",
    "\n",
    "\n",
    "X_train, X_test = oneHotEncoding(X, XforPredictions)\n",
    "X_train, X_test = imputePlus(X_train ,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Predictions: [1.876  1.3383 1.6805 ... 1.3981 1.5591 1.5873]\n"
    }
   ],
   "source": [
    "# Make Predictions!\n",
    "yPredictions =  model.predict(X_test)# model.predict(X_test)# None #TODO TODO TODO TODO TODO TODO TODO TODO\n",
    "print(\"Predictions:\", yPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "id  AveragePrice\n0        0        1.8760\n1        1        1.3383\n2        2        1.6805\n3        3        1.8574\n4        4        1.5926\n...    ...           ...\n5470  5470        1.7320\n5471  5471        1.4282\n5472  5472        1.3981\n5473  5473        1.5591\n5474  5474        1.5873\n\n[5475 rows x 2 columns]\n"
    }
   ],
   "source": [
    "# Save to CSV File!\n",
    "XforPredictions =  MyDataFrame[features]\n",
    "output = pd.DataFrame({'id': XforPredictions.index, 'AveragePrice': yPredictions})\n",
    "output.to_csv('avocado-submission.csv', index=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloaded pyctfsglib.py: True\n"
    }
   ],
   "source": [
    "# Download CTFSG Grader Libraries\n",
    "import urllib.request, os\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/alttablabs/ctfsg-utils/master/pyctfsglib.py', './pyctfsglib.py')\n",
    "print('Downloaded pyctfsglib.py:', 'pyctfsglib.py' in os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "DSGraderClient: Successfully Connected!\n[SERVER] MOTD: CHECK your USER_TOKEN and GRADER_URL HTTP address! I'm AVOCADO_PRICE TEST_GRADER_1\n"
    }
   ],
   "source": [
    "# Connect to graders\n",
    "import pyctfsglib as ctfsg\n",
    "import random\n",
    "\n",
    "USER_TOKEN = \"MXhtGfdjdsUfiEKTHHEuVGohZESBdMiHrFkmYqNqIFfcWOHGvcubvHJvnxpAqRMh\" # You need to fill this up\n",
    "GRADER_URL = random.choice([\n",
    "\"http://challenges.csdc20t.ctf.sg:30001/\", \"http://challenges.csdc20t.ctf.sg:30002/\"\n",
    "])\n",
    "grader = ctfsg.DSGraderClient(GRADER_URL, USER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ProofOfWork Challenge =>  ('CTFSGRB4964c7954faccdc6388e9a04b2be6c02', 22)\nProofOfWork Answer Found! =>  1459974\n"
    },
    {
     "data": {
      "text/plain": "'{\"challenge\":{\"name\":\"Avocado Prices\"},\"id\":\"ck8mt5qvg6v420868r669ol2k\",\"status\":\"PARTIALLY_CORRECT\",\"multiplier\":0.1204,\"submittedBy\":{\"username\":\"nyjc-1\"},\"createdAt\":\"2020-04-05T08:52:53Z\"}'"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.submitFile('avocado-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}